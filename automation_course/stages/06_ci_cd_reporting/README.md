# –ú–æ–¥—É–ª—å 6: CI/CD –∏ –æ—Ç—á–µ—Ç–Ω–æ—Å—Ç—å

## üéØ –¶–µ–ª–∏ –º–æ–¥—É–ª—è (3 –Ω–µ–¥–µ–ª–∏ / 12 –∑–∞–Ω—è—Ç–∏–π)

**–ü–æ –æ–∫–æ–Ω—á–∞–Ω–∏–∏ –º–æ–¥—É–ª—è —Å—Ç—É–¥–µ–Ω—Ç —Å–º–æ–∂–µ—Ç:**
- –ù–∞—Å—Ç—Ä–∞–∏–≤–∞—Ç—å CI/CD pipelines –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤
- –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ –æ—Ç—á–µ—Ç—ã –æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏
- –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–µ—Å—Ç—ã –≤ GitLab CI, GitHub Actions –∏ Jenkins
- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∏ –∞–ª–µ—Ä—Ç–∏–Ω–≥–∞ —Ç–µ—Å—Ç–æ–≤
- **–†–µ–∞–ª–∏–∑–æ–≤—ã–≤–∞—Ç—å —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ production-like —Å—Ä–µ–¥–∞—Ö**
- **–°–æ–∑–¥–∞–≤–∞—Ç—å dashboards –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞**
- **–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ç–µ—Å—Ç–æ–≤ –≤ CI**
- **–ù–∞—Å—Ç—Ä–∞–∏–≤–∞—Ç—å security –∏ secrets management**
- **–†–µ–∞–ª–∏–∑–æ–≤—ã–≤–∞—Ç—å —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ —Ä–∞–∑–Ω—ã—Ö —Å—Ä–µ–¥–∞—Ö (dev/staging/prod)**
- **–°–æ–∑–¥–∞–≤–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –∏ KPI –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è**

## üë®‚Äçüè´ –ú–µ—Ç–æ–¥–∏—á–µ—Å–∫–∏–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –¥–ª—è –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—è

### –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è DevOps –ø—Ä–∞–∫—Ç–∏–∫ –≤ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ:

**üéØ –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –ø—Ä–µ–ø–æ–¥–∞–≤–∞–Ω–∏—è CI/CD:**
- **–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∞—è –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ—Å—Ç—å:** –†–∞–±–æ—Ç–∞ —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ CI —Å–∏—Å—Ç–µ–º–∞–º–∏
- **Infrastructure as Code:** –ü–æ–Ω–∏–º–∞–Ω–∏–µ –∫–∞–∫ –∫–æ–¥–∞ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã
- **Monitoring mindset:** –£–º–µ–Ω–∏–µ –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏
- **Troubleshooting skills:** –ù–∞–≤—ã–∫–∏ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –ø—Ä–æ–±–ª–µ–º –≤ CI
- **Security awareness:** –ü–æ–Ω–∏–º–∞–Ω–∏–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ CI/CD –ø—Ä–æ—Ü–µ—Å—Å–æ–≤
- **Production readiness:** –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ —Ä–∞–±–æ—Ç–µ –≤ production —Å—Ä–µ–¥–∞—Ö
- **Metrics-driven approach:** –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π

### üõ†Ô∏è –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã DevOps –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫–∞

#### –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞:
- **Grafana** - —Å–æ–∑–¥–∞–Ω–∏–µ dashboards –¥–ª—è –º–µ—Ç—Ä–∏–∫ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
- **Prometheus** - —Å–±–æ—Ä –∏ —Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
- **ELK Stack** (Elasticsearch, Logstash, Kibana) - –∞–Ω–∞–ª–∏–∑ –ª–æ–≥–æ–≤
- **Datadog** - –æ–±–ª–∞—á–Ω—ã–π monitoring
- **New Relic** - application performance monitoring

#### Security tools –¥–ª—è CI/CD:
- **Snyk** - —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —É—è–∑–≤–∏–º–æ—Å—Ç–µ–π –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
- **SonarQube** - static code analysis
- **OWASP ZAP** - security testing
- **HashiCorp Vault** - secrets management

#### –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –∫–æ–º–∞–Ω–¥—ã CI/CD:
```bash
# –õ–æ–∫–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ GitLab CI
gitlab-runner exec docker test-job-name

# –õ–æ–∫–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ GitHub Actions
act -j test-job-name

# –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ pipeline –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
watch -n 5 'curl -s "https://gitlab.example.com/api/v4/projects/123/pipelines"'

# –ê–Ω–∞–ª–∏–∑ performance —Ç–µ—Å—Ç–æ–≤
python scripts/analyze_performance.py --input reports/ --output dashboard/

# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è security report
snyk test --json > security-report.json

# Backup –∏ restore CI –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π
python scripts/backup_ci_config.py --project my-project --output backup/
```

**üìã –¢—Ä–µ–±—É–µ–º—ã–µ —Ä–µ—Å—É—Ä—Å—ã:**
- –î–æ—Å—Ç—É–ø –∫ CI/CD –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞–º (GitLab, GitHub, Jenkins)
- Docker –æ–±—Ä–∞–∑—ã –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
- Monitoring –∏ logging –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
- Sample repositories —Å —Ç–µ—Å—Ç–∞–º–∏
- **–ì–æ—Ç–æ–≤—ã–µ pipeline templates**
- **Test environments (dev/staging/prod access)**
- **Monitoring dashboards –∏ alerting systems**
- **Security scanning tools**
- **Performance testing infrastructure**

### üìã –ü–æ–¥—Ä–æ–±–Ω—ã–π —Ç–∞–π–º–∏–Ω–≥ –∑–∞–Ω—è—Ç–∏–π –º–æ–¥—É–ª—è 6

#### –ó–∞–Ω—è—Ç–∏–µ 6.1: GitLab CI Pipeline fundamentals (90 –º–∏–Ω—É—Ç)

**0-15 –º–∏–Ω:** –í–≤–µ–¥–µ–Ω–∏–µ –≤ CI/CD –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏
- –ß—Ç–æ —Ç–∞–∫–æ–µ Continuous Integration –∏ Delivery
- –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
- **–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ pipeline**

**15-35 –º–∏–Ω:** –¢–µ–æ—Ä–∏—è - –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ GitLab CI
- Jobs, stages, –∏ pipeline workflow
- Variables –∏ secrets management
- Artifacts –∏ caching –º–µ—Ö–∞–Ω–∏–∑–º
- **–ñ–∏–≤–∞—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è pipeline —Å—Ç—Ä—É–∫—Ç—É—Ä—ã**

**35-60 –º–∏–Ω:** –ü—Ä–∞–∫—Ç–∏–∫–∞ - –°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑–æ–≤–æ–≥–æ pipeline
- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ .gitlab-ci.yml —Ñ–∞–π–ª–∞
- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è test jobs
- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ artifact —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
- **Interactive coding session**

**60-80 –º–∏–Ω:** –°–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞
- –°—Ç—É–¥–µ–Ω—Ç—ã —Å–æ–∑–¥–∞—é—Ç —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ pipelines
- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ä–∞–∑–Ω—ã—Ö stages
- **–ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–∞—è –ø–æ–º–æ—â—å –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—è**

**80-90 –º–∏–Ω:** –ó–∞–∫—Ä–µ–ø–ª–µ–Ω–∏–µ –º–∞—Ç–µ—Ä–∏–∞–ª–∞
- –†–∞–∑–±–æ—Ä —Ç–∏–ø–∏—á–Ω—ã—Ö –æ—à–∏–±–æ–∫
- –û—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã
- –î–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ

#### –ó–∞–Ω—è—Ç–∏–µ 6.2: –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ CI/CD (90 –º–∏–Ω—É—Ç)

**0-20 –º–∏–Ω:** –¢–µ–æ—Ä–∏—è - Advanced CI/CD features
- Matrix builds –∏ parallel execution
- Conditional job execution
- Trigger jobs –∏ child pipelines
- **–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ–¥—Ö–æ–¥–æ–≤ —Ä–∞–∑–Ω—ã—Ö –ø–ª–∞—Ç—Ñ–æ—Ä–º**

**20-45 –º–∏–Ω:** –ü—Ä–∞–∫—Ç–∏–∫–∞ - Complex pipeline scenarios
- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ multi-environment deployments
- Implementation of approval gates
- Integration with external services
- **Live demonstration**

**45-70 –º–∏–Ω:** –ü—Ä–∞–∫—Ç–∏–∫–∞ - Monitoring –∏ alerting
- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Slack/GitLab notifications
- Creation of custom metrics
- Implementation of failure analysis
- **Hands-on configuration**

**70-85 –º–∏–Ω:** –°–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–∞—è —Ä–∞–±–æ—Ç–∞
- Students configure monitoring for their pipelines
- Setup alerting rules
- **Personal consultations**

**85-90 –º–∏–Ω:** –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –∑–∞–Ω—è—Ç–∏—è
- Review of accomplished work
- Homework assignment

#### –ó–∞–Ω—è—Ç–∏–µ 6.3: Reporting –∏ dashboard creation (90 –º–∏–Ω—É—Ç)

**0-25 –º–∏–Ω:** –¢–µ–æ—Ä–∏—è - Allure –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ –æ—Ç—á–µ—Ç—ã
- Allure framework capabilities
- Custom reporters development
- Integration with CI systems
- **Showcase of professional reports**

**25-50 –º–∏–Ω:** –ü—Ä–∞–∫—Ç–∏–∫–∞ - Dashboard creation
- Grafana dashboard setup
- Custom metrics visualization
- Real-time monitoring panels
- **Interactive dashboard building**

**50-75 –º–∏–Ω:** –°–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞
- –°–æ–∑–¥–∞–Ω–∏–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö dashboards
- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–µ—Ç—Ä–∏–∫ –∏ –∞–ª–µ—Ä—Ç–æ–≤
- **Individual support**

**75-90 –º–∏–Ω:** –ü–æ–¥–≤–µ–¥–µ–Ω–∏–µ –∏—Ç–æ–≥–æ–≤ –º–æ–¥—É–ª—è
- Review of all CI/CD concepts
- Final Q&A session
- Course completion certificate
- **Next steps recommendations**

**‚è∞ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∑–∞–Ω—è—Ç–∏–π –ø–æ CI/CD:**
- 15 –º–∏–Ω: –¢–µ–æ—Ä–∏—è –∏ best practices
- 30 –º–∏–Ω: Live configuration demos
- 30 –º–∏–Ω: Hands-on pipeline setup
- 15 –º–∏–Ω: Troubleshooting –∏ debugging

## ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∞ CI/CD Pipelines

### GitLab CI Pipeline –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ —Ç–µ—Å—Ç–æ–≤

```yaml
# .gitlab-ci.yml - –ü–û–õ–ù–´–ô PIPELINE –î–õ–Ø –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø

stages:
  - setup
  - test
  - report
  - deploy

variables:
  # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
  PYTHON_VERSION: "3.11"
  PLAYWRIGHT_BROWSERS_PATH: "$CI_PROJECT_DIR/ms-playwright"
  REPORTS_DIR: "$CI_PROJECT_DIR/reports"
  
  # Environment variables
  TEST_ENVIRONMENT: "staging"
  BASE_URL: "https://staging.example.com"

# SETUP STAGE
install_dependencies:
  stage: setup
  image: python:$PYTHON_VERSION
  before_script:
    - apt-get update && apt-get install -y curl jq
    - pip install --upgrade pip
  script:
    - pip install -r requirements.txt
    - playwright install --with-deps chromium firefox webkit
    - python -m pytest --collect-only tests/  # –ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ —Ç–µ—Å—Ç—ã —Å–æ–±–∏—Ä–∞—é—Ç—Å—è
  artifacts:
    paths:
      - .venv/
      - ms-playwright/
    expire_in: 1 hour
  cache:
    key: ${CI_COMMIT_REF_SLUG}
    paths:
      - .cache/pip/
      - ms-playwright/

# UNIT TESTS STAGE
unit_tests:
  stage: test
  image: python:$PYTHON_VERSION
  services:
    - postgres:13
  variables:
    POSTGRES_DB: test_db
    POSTGRES_USER: test_user
    POSTGRES_PASSWORD: test_pass
  script:
    - source .venv/bin/activate  # –ï—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è virtual environment
    - pytest tests/unit/ --junitxml=reports/unit-tests.xml --cov=src --cov-report=xml:reports/coverage.xml
  artifacts:
    reports:
      junit: reports/unit-tests.xml
      coverage_report:
        coverage_format: cobertura
        path: reports/coverage.xml
    paths:
      - reports/
    expire_in: 1 week
  coverage: '/TOTAL.*\s+(\d+%)$/'
  allow_failure: false

# API TESTS STAGE
api_tests:
  stage: test
  image: python:$PYTHON_VERSION
  script:
    - pytest tests/api/ --junitxml=reports/api-tests.xml -v
  artifacts:
    reports:
      junit: reports/api-tests.xml
    paths:
      - reports/
    expire_in: 1 week
  allow_failure: false

# UI TESTS STAGE
ui_tests:
  stage: test
  image: mcr.microsoft.com/playwright/python:v1.40.0-focal
  before_script:
    - pip install -r requirements.txt
  parallel:
    matrix:
      - BROWSER: [chromium, firefox, webkit]
        DEVICE: [desktop, mobile]
  script:
    - |
      pytest tests/ui/ \
        --browser=$BROWSER \
        --device=$DEVICE \
        --junitxml=reports/ui-tests-$BROWSER-$DEVICE.xml \
        --video=retain-on-failure \
        --screenshot=only-on-failure \
        --tracing=retain-on-failure
  artifacts:
    reports:
      junit: reports/ui-tests-$BROWSER-$DEVICE.xml
    paths:
      - reports/videos/
      - reports/screenshots/
      - reports/traces/
    expire_in: 1 week
    when: always
  allow_failure: true  # UI —Ç–µ—Å—Ç—ã –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω—ã

# PERFORMANCE TESTS STAGE
performance_tests:
  stage: test
  image: python:$PYTHON_VERSION
  script:
    - |
      pytest tests/performance/ \
        --junitxml=reports/performance-tests.xml \
        --html=reports/performance-report.html
  artifacts:
    reports:
      junit: reports/performance-tests.xml
    paths:
      - reports/performance-report.html
    expire_in: 1 month
  only:
    - schedules  # –ó–∞–ø—É—Å–∫ –ø–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—é
    - master     # –ò–ª–∏ —Ç–æ–ª—å–∫–æ –≤ master –≤–µ—Ç–∫–µ

# REPORT GENERATION STAGE
generate_reports:
  stage: report
  image: python:$PYTHON_VERSION
  needs:
    - job: unit_tests
    - job: api_tests
    - job: ui_tests
    - job: performance_tests
  script:
    - pip install allure-pytest
    - |
      allure generate \
        reports/allure-results/ \
        -o reports/allure-report/ \
        --clean
  artifacts:
    paths:
      - reports/allure-report/
    expire_in: 1 month
  dependencies:
    - unit_tests
    - api_tests
    - ui_tests
    - performance_tests

# DASHBOARD AND METRICS
publish_metrics:
  stage: report
  image: python:$PYTHON_VERSION
  script:
    - |
      # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫ –¥–ª—è dashboard
      python scripts/generate_metrics.py \
        --input-reports reports/ \
        --output-json reports/metrics.json
  artifacts:
    reports:
      metrics: reports/metrics.json
    paths:
      - reports/metrics.json
    expire_in: 1 year

# DEPLOYMENT STAGE (Conditional)
deploy_if_tests_pass:
  stage: deploy
  image: docker:latest
  services:
    - docker:dind
  before_script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
  script:
    - |
      if [ "$CI_PIPELINE_SOURCE" = "merge_request_event" ]; then
        echo "Deploying to staging environment..."
        docker build -t $CI_REGISTRY_IMAGE:staging-$CI_COMMIT_SHA .
        docker push $CI_REGISTRY_IMAGE:staging-$CI_COMMIT_SHA
      elif [ "$CI_COMMIT_BRANCH" = "master" ]; then
        echo "Deploying to production..."
        docker build -t $CI_REGISTRY_IMAGE:prod-$CI_COMMIT_TAG .
        docker push $CI_REGISTRY_IMAGE:prod-$CI_COMMIT_TAG
      fi
  only:
    - merge_requests
    - master@your-group/your-project
  when: on_success

# SCHEDULED JOBS
scheduled_regression:
  stage: test
  image: python:$PYTHON_VERSION
  script:
    - pytest tests/regression/ --junitxml=reports/regression-tests.xml
  artifacts:
    reports:
      junit: reports/regression-tests.xml
  only:
    - schedules

# TRIGGER JOBS
trigger_external_pipeline:
  stage: deploy
  trigger:
    include:
      - project: 'infrastructure/deployment'
        file: '.gitlab-ci.yml'
    strategy: depend
  only:
    - master
  when: on_success

# CUSTOM TEMPLATES SECTION
.custom_cache_template: &custom_cache_definition
  cache:
    key: "${CI_JOB_NAME}"
    paths:
      - .venv/
      - .npm/
      - node_modules/
    policy: pull-push

.custom_artifact_template: &custom_artifact_definition
  artifacts:
    paths:
      - reports/
    reports:
      junit: reports/test-results.xml
    expire_in: 1 week
    when: always

# ENVIRONMENT-SPECIFIC CONFIGURATIONS
.environment_variables_template: &environment_variables
  variables:
    DB_HOST: $DB_HOST
    DB_PORT: $DB_PORT
    DB_NAME: $DB_NAME
    DB_USER: $DB_USER
    DB_PASS: $DB_PASS
    API_BASE_URL: $API_BASE_URL
    WEB_BASE_URL: $WEB_BASE_URL

# –ü–û–õ–ï–ó–ù–´–ï –°–ö–†–ò–ü–¢–´ –î–õ–Ø CI:

# scripts/wait_for_services.py
"""
–°–∫—Ä–∏–ø—Ç –æ–∂–∏–¥–∞–Ω–∏—è readiness —Å–µ—Ä–≤–∏—Å–æ–≤
"""

import time
import requests
from typing import List

def wait_for_services(services: List[str], timeout: int = 300):
    """–û–∂–∏–¥–∞–Ω–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–∏—Å–æ–≤"""
    start_time = time.time()
    
    for service_url in services:
        while time.time() - start_time < timeout:
            try:
                response = requests.get(service_url, timeout=5)
                if response.status_code == 200:
                    print(f"‚úÖ Service {service_url} is ready")
                    break
            except requests.RequestException:
                pass
            
            print(f"‚è≥ Waiting for {service_url}...")
            time.sleep(5)
        else:
            raise TimeoutError(f"Service {service_url} did not become ready within {timeout} seconds")

if __name__ == "__main__":
    import sys
    services = sys.argv[1:] if len(sys.argv) > 1 else ["http://localhost:8000/health"]
    wait_for_services(services)
```

### GitHub Actions Workflow

```yaml
# .github/workflows/test-automation.yml

name: Test Automation Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    - cron: '0 2 * * 1'  # –ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ –ø–æ –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫–∞–º

env:
  PYTHON_VERSION: '3.11'
  PLAYWRIGHT_BROWSERS_PATH: '${{ github.workspace }}/ms-playwright'

jobs:
  setup:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: |
            ~/.cache/pip
            ${{ env.PLAYWRIGHT_BROWSERS_PATH }}
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          playwright install --with-deps
      
      - name: Validate test collection
        run: python -m pytest --collect-only tests/

  unit-tests:
    needs: setup
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:13
        env:
          POSTGRES_DB: testdb
          POSTGRES_USER: testuser
          POSTGRES_PASSWORD: testpass
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    steps:
      - uses: actions/checkout@v4
      
      - name: Restore cache
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
      
      - name: Run unit tests
        run: |
          pytest tests/unit/ \
            --junitxml=reports/unit-test-results.xml \
            --cov=src \
            --cov-report=xml:reports/coverage.xml \
            --cov-report=html:reports/coverage-html
          
      - name: Publish Test Results
        uses: EnricoMi/publish-unit-test-result-action@v2
        if: always()
        with:
          files: reports/unit-test-results.xml
          
      - name: Publish Coverage
        uses: codecov/codecov-action@v3
        with:
          file: ./reports/coverage.xml
          flags: unittests
          name: codecov-umbrella

  ui-tests:
    needs: setup
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        browser: [chromium, firefox, webkit]
        shard: [1/3, 2/3, 3/3]
    steps:
      - uses: actions/checkout@v4
      
      - name: Restore Playwright browsers
        uses: actions/cache@v3
        with:
          path: ${{ env.PLAYWRIGHT_BROWSERS_PATH }}
          key: playwright-browsers-${{ runner.os }}
      
      - name: Run UI tests
        run: |
          pytest tests/ui/ \
            --browser=${{ matrix.browser }} \
            --shard=${{ matrix.shard }} \
            --junitxml=reports/ui-test-results-${{ matrix.browser }}-${{ matrix.shard }}.xml \
            --video=retain-on-failure \
            --screenshot=only-on-failure \
            --tracing=retain-on-failure
          
      - name: Upload test artifacts
        uses: actions/upload-artifact@v3
        if: failure()
        with:
          name: test-results-${{ matrix.browser }}-${{ matrix.shard }}
          path: |
            reports/videos/
            reports/screenshots/
            reports/traces/
          retention-days: 7

  generate-dashboard:
    needs: [unit-tests, ui-tests]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Download all test results
        uses: actions/download-artifact@v3
        with:
          path: downloaded-artifacts
      
      - name: Generate Allure Report
        run: |
          docker run --rm \
            -v "${PWD}/downloaded-artifacts:/results" \
            -v "${PWD}/reports/allure-report:/allure-report" \
            frankescobar/allure-docker-service:2.21.0 \
            allure generate /results/*/*/reports/*.xml -o /allure-report --clean
      
      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./reports/allure-report
          destination_dir: test-reports/${{ github.sha }}

  notify-slack:
    needs: [unit-tests, ui-tests]
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Send Slack notification
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          channel: '#test-notifications'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK }}
```

## üìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–æ–≤ –∏ –º–µ—Ç—Ä–∏–∫

### Allure Framework –¥–ª—è –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –æ—Ç—á–µ—Ç–æ–≤

```python
# –ü–†–û–§–ï–°–°–ò–û–ù–ê–õ–¨–ù–´–ï –û–¢–ß–ï–¢–´ –° ALLURE

class AllureReporting:
    def __init__(self):
        self.report_templates = {}
        self.metrics_collectors = {}
    
    def allure_decorators_examples(self):
        """–ü—Ä–∏–º–µ—Ä—ã –¥–µ–∫–æ—Ä–∞—Ç–æ—Ä–æ–≤ Allure"""
        
        import allure
        import pytest
        
        @allure.feature("User Management")
        @allure.story("User Registration")
        @allure.severity(allure.severity_level.CRITICAL)
        @pytest.mark.parametrize("user_type", ["regular", "premium", "admin"])
        def test_user_registration(page, user_type):
            """–¢–µ—Å—Ç —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å Allure –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è–º–∏"""
            
            with allure.step("Navigate to registration page"):
                page.goto("/register")
                allure.attach(
                    page.screenshot(),
                    name="Registration page",
                    attachment_type=allure.attachment_type.PNG
                )
            
            with allure.step(f"Fill registration form for {user_type} user"):
                page.fill("#email", f"{user_type}@test.com")
                page.fill("#password", "securePassword123")
                
                if user_type == "premium":
                    page.check("#premium-plan")
                
                allure.attach(
                    page.content(),
                    name="Form filled",
                    attachment_type=allure.attachment_type.HTML
                )
            
            with allure.step("Submit registration form"):
                with page.expect_response("**/api/register") as response_info:
                    page.click("#register-btn")
                
                response = response_info.value
                allure.attach(
                    str(response.status),
                    name="API Response Status",
                    attachment_type=allure.attachment_type.TEXT
                )
            
            with allure.step("Verify successful registration"):
                expect(page).to_have_url("/dashboard")
                welcome_message = page.locator(".welcome-message")
                expect(welcome_message).to_be_visible()
                
                allure.attach(
                    welcome_message.text_content(),
                    name="Welcome message",
                    attachment_type=allure.attachment_type.TEXT
                )
    
    def custom_allure_attachments(self, page):
        """–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–µ –≤–ª–æ–∂–µ–Ω–∏—è Allure"""
        
        import allure
        import json
        from datetime import datetime
        
        def attach_test_metadata(test_name, browser_info, test_data):
            """–ü—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —Ç–µ—Å—Ç–∞"""
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –±—Ä–∞—É–∑–µ—Ä–µ
            allure.attach(
                json.dumps(browser_info, indent=2),
                name="Browser Information",
                attachment_type=allure.attachment_type.JSON
            )
            
            # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            allure.attach(
                json.dumps(test_data, indent=2),
                name="Test Data",
                attachment_type=allure.attachment_type.JSON
            )
            
            # –°–∫—Ä–∏–Ω—à–æ—Ç —Å timestamp
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            screenshot = page.screenshot()
            allure.attach(
                screenshot,
                name=f"Screenshoot at {timestamp}",
                attachment_type=allure.attachment_type.PNG
            )
        
        def attach_network_logs(page):
            """–ü—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–∏–µ network –ª–æ–≥–æ–≤"""
            
            # –°–±–æ—Ä network –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
            network_info = page.evaluate("""() => {
                return performance.getEntriesByType('navigation')[0];
            }""")
            
            allure.attach(
                json.dumps(network_info, indent=2, default=str),
                name="Network Performance Metrics",
                attachment_type=allure.attachment_type.JSON
            )
        
        def attach_console_logs(page):
            """–ü—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–∏–µ console –ª–æ–≥–æ–≤"""
            
            logs = []
            page.on("console", lambda msg: logs.append({
                "type": msg.type,
                "text": msg.text,
                "location": msg.location
            }))
            
            # –í –∫–æ–Ω—Ü–µ —Ç–µ—Å—Ç–∞ –ø—Ä–∏–∫—Ä–µ–ø–ª—è–µ–º –ª–æ–≥–∏
            def attach_logs():
                allure.attach(
                    json.dumps(logs, indent=2),
                    name="Browser Console Logs",
                    attachment_type=allure.attachment_type.JSON
                )
            
            return attach_logs
    
    def allure_labels_and_links(self):
        """Allure labels –∏ —Å—Å—ã–ª–∫–∏"""
        
        import allure
        
        @allure.label("layer", "UI")
        @allure.label("owner", "qa-team")
        @allure.link("https://jira.example.com/browse/PROJ-123", name="JIRA Issue")
        @allure.issue("BUG-456", "Known issue with login")
        @allure.testcase("TC-789", "Test case specification")
        def test_with_labels_and_links(page):
            """–¢–µ—Å—Ç —Å –ø–æ–ª–Ω–æ–π –∞–Ω–Ω–æ—Ç–∞—Ü–∏–µ–π Allure"""
            pass

# –ì–ï–ù–ï–†–ê–¶–ò–Ø –ú–ï–¢–†–ò–ö –ò DASHBOARDS:

class MetricsAndDashboards:
    def __init__(self):
        self.metrics_collector = {}
        self.dashboard_generator = {}
    
    def test_metrics_collector(self):
        """–°–±–æ—Ä –º–µ—Ç—Ä–∏–∫ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
        
        import json
        from datetime import datetime
        from collections import defaultdict
        
        class TestMetricsCollector:
            def __init__(self):
                self.metrics = defaultdict(list)
                self.start_time = datetime.now()
            
            def collect_test_result(self, test_name, status, duration, metadata=None):
                """–°–±–æ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞"""
                
                metric_entry = {
                    "test_name": test_name,
                    "status": status,
                    "duration_ms": duration * 1000,  # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã
                    "timestamp": datetime.now().isoformat(),
                    "metadata": metadata or {}
                }
                
                self.metrics[test_name].append(metric_entry)
            
            def collect_performance_metrics(self, page, test_name):
                """–°–±–æ—Ä performance –º–µ—Ç—Ä–∏–∫"""
                
                perf_metrics = page.evaluate("""() => {
                    const nav = performance.getEntriesByType('navigation')[0];
                    const paint = performance.getEntriesByType('paint');
                    
                    return {
                        pageLoadTime: nav.loadEventEnd - nav.fetchStart,
                        domContentLoaded: nav.domContentLoadedEventEnd - nav.fetchStart,
                        firstPaint: paint.find(p => p.name === 'first-paint')?.startTime,
                        firstContentfulPaint: paint.find(p => p.name === 'first-contentful-paint')?.startTime
                    };
                }""")
                
                self.metrics[f"{test_name}_perf"].append({
                    "timestamp": datetime.now().isoformat(),
                    "metrics": perf_metrics
                })
            
            def generate_summary_report(self):
                """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–≤–æ–¥–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
                
                summary = {
                    "report_generated": datetime.now().isoformat(),
                    "total_tests": sum(len(results) for results in self.metrics.values()),
                    "passed_tests": sum(1 for results in self.metrics.values() 
                                      for result in results if result["status"] == "passed"),
                    "failed_tests": sum(1 for results in self.metrics.values() 
                                      for result in results if result["status"] == "failed"),
                    "average_duration": self._calculate_average_duration(),
                    "slowest_tests": self._get_slowest_tests(limit=10),
                    "flaky_tests": self._identify_flaky_tests()
                }
                
                return summary
            
            def _calculate_average_duration(self):
                """–†–∞—Å—á–µ—Ç —Å—Ä–µ–¥–Ω–µ–π –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ç–µ—Å—Ç–æ–≤"""
                all_durations = [
                    result["duration_ms"] 
                    for results in self.metrics.values() 
                    for result in results 
                    if "duration_ms" in result
                ]
                return sum(all_durations) / len(all_durations) if all_durations else 0
            
            def _get_slowest_tests(self, limit=10):
                """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–∞–º—ã—Ö –º–µ–¥–ª–µ–Ω–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤"""
                test_averages = []
                
                for test_name, results in self.metrics.items():
                    durations = [r["duration_ms"] for r in results if "duration_ms" in r]
                    if durations:
                        avg_duration = sum(durations) / len(durations)
                        test_averages.append((test_name, avg_duration))
                
                return sorted(test_averages, key=lambda x: x[1], reverse=True)[:limit]
            
            def _identify_flaky_tests(self, threshold=0.3):
                """–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è flaky —Ç–µ—Å—Ç–æ–≤"""
                flaky_tests = []
                
                for test_name, results in self.metrics.items():
                    if len(results) < 3:  # –ù—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 3 –∑–∞–ø—É—Å–∫–∞
                        continue
                    
                    statuses = [r["status"] for r in results]
                    pass_rate = statuses.count("passed") / len(statuses)
                    
                    if 0.3 <= pass_rate <= 0.7:  # –°–∏–ª—å–Ω–æ –∫–æ–ª–µ–±–ª—é—â–∏–π—Å—è pass rate
                        flaky_tests.append({
                            "test_name": test_name,
                            "pass_rate": pass_rate,
                            "total_runs": len(results),
                            "recent_status": statuses[-5:]  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 5 –∑–∞–ø—É—Å–∫–æ–≤
                        })
                
                return flaky_tests
        
        return TestMetricsCollector()
    
    def dashboard_generation(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è dashboard –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"""
        
        def generate_html_dashboard(metrics_data, output_file="dashboard.html"):
            """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è HTML dashboard"""
            
            html_template = """
            <!DOCTYPE html>
            <html>
            <head>
                <title>Test Automation Dashboard</title>
                <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
                <style>
                    body { font-family: Arial, sans-serif; margin: 20px; }
                    .metric-card { 
                        border: 1px solid #ddd; 
                        padding: 15px; 
                        margin: 10px; 
                        border-radius: 5px;
                        display: inline-block;
                        min-width: 200px;
                    }
                    .passed { background-color: #d4edda; border-color: #c3e6cb; }
                    .failed { background-color: #f8d7da; border-color: #f5c6cb; }
                    .chart-container { width: 600px; height: 400px; margin: 20px; }
                </style>
            </head>
            <body>
                <h1>Test Automation Dashboard</h1>
                
                <div class="metric-card passed">
                    <h3>Passed Tests</h3>
                    <h2>{passed_count}</h2>
                </div>
                
                <div class="metric-card failed">
                    <h3>Failed Tests</h3>
                    <h2>{failed_count}</h2>
                </div>
                
                <div class="metric-card">
                    <h3>Pass Rate</h3>
                    <h2>{pass_rate:.1f}%</h2>
                </div>
                
                <div class="metric-card">
                    <h3>Average Duration</h3>
                    <h2>{avg_duration:.2f}s</h2>
                </div>
                
                <div class="chart-container">
                    <canvas id="durationChart"></canvas>
                </div>
                
                <div class="chart-container">
                    <canvas id="statusChart"></canvas>
                </div>
                
                <script>
                    // Duration chart
                    new Chart(document.getElementById('durationChart'), {{
                        type: 'bar',
                        data: {{
                            labels: {slowest_test_names},
                            datasets: [{{
                                label: 'Average Duration (seconds)',
                                data: {slowest_test_durations},
                                backgroundColor: 'rgba(54, 162, 235, 0.2)',
                                borderColor: 'rgba(54, 162, 235, 1)',
                                borderWidth: 1
                            }}]
                        }},
                        options: {{
                            responsive: true,
                            scales: {{
                                y: {{
                                    beginAtZero: true
                                }}
                            }}
                        }}
                    }});
                    
                    // Status chart
                    new Chart(document.getElementById('statusChart'), {{
                        type: 'doughnut',
                        data: {{
                            labels: ['Passed', 'Failed'],
                            datasets: [{{
                                data: [{passed_count}, {failed_count}],
                                backgroundColor: ['#4CAF50', '#F44336']
                            }}]
                        }},
                        options: {{
                            responsive: true
                        }}
                    }});
                </script>
            </body>
            </html>
            """
            
            # –ü–æ–¥—Å—Ç–∞–Ω–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            passed_count = metrics_data["passed_tests"]
            failed_count = metrics_data["failed_tests"]
            pass_rate = (passed_count / (passed_count + failed_count)) * 100 if (passed_count + failed_count) > 0 else 0
            avg_duration = metrics_data["average_duration"] / 1000  # –í —Å–µ–∫—É–Ω–¥–∞—Ö
            
            # –î–∞–Ω–Ω—ã–µ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤
            slowest_tests = metrics_data["slowest_tests"][:5]
            slowest_test_names = json.dumps([test[0] for test in slowest_tests])
            slowest_test_durations = json.dumps([test[1]/1000 for test in slowest_tests])  # –í —Å–µ–∫—É–Ω–¥–∞—Ö
            
            # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ HTML
            html_content = html_template.format(
                passed_count=passed_count,
                failed_count=failed_count,
                pass_rate=pass_rate,
                avg_duration=avg_duration,
                slowest_test_names=slowest_test_names,
                slowest_test_durations=slowest_test_durations
            )
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(html_content)
            
            return output_file

# –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø –° MONITORING –°–ò–°–¢–ï–ú–ê–ú–ò:

class MonitoringIntegration:
    def prometheus_metrics_export(self):
        """–≠–∫—Å–ø–æ—Ä—Ç –º–µ—Ç—Ä–∏–∫ –≤ Prometheus"""
        
        def generate_prometheus_metrics(metrics_data, output_file="metrics.prom"):
            """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫ –≤ —Ñ–æ—Ä–º–∞—Ç–µ Prometheus"""
            
            prometheus_content = f"""
            # TYPE test_total counter
            # HELP test_total Total number of tests executed
            test_total {{status="passed"}} {metrics_data["passed_tests"]}
            test_total {{status="failed"}} {metrics_data["failed_tests"]}
            
            # TYPE test_duration_seconds gauge
            # HELP test_duration_seconds Average test duration in seconds
            test_duration_seconds {{type="average"}} {metrics_data["average_duration"] / 1000}
            
            # TYPE test_flaky_count gauge
            # HELP test_flaky_count Number of flaky tests identified
            test_flaky_count {len(metrics_data["flaky_tests"])}
            
            # TYPE test_slow_count gauge
            # HELP test_slow_count Number of tests slower than threshold
            test_slow_count {len([t for t in metrics_data["slowest_tests"] if t[1] > 10000])}
            """
            
            with open(output_file, 'w') as f:
                f.write(prometheus_content)
            
            return output_file
    
    def slack_notification_integration(self):
        """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Slack notifications"""
        
        def send_slack_notification(webhook_url, metrics_data):
            """–û—Ç–ø—Ä–∞–≤–∫–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –≤ Slack"""
            
            import requests
            import json
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ü–≤–µ—Ç–∞ —Å–æ–æ–±—â–µ–Ω–∏—è
            pass_rate = metrics_data["passed_tests"] / (metrics_data["passed_tests"] + metrics_data["failed_tests"])
            color = "good" if pass_rate >= 0.9 else "warning" if pass_rate >= 0.8 else "danger"
            
            # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è
            message = {
                "attachments": [{
                    "color": color,
                    "title": "Test Automation Results",
                    "fields": [
                        {
                            "title": "Total Tests",
                            "value": str(metrics_data["passed_tests"] + metrics_data["failed_tests"]),
                            "short": True
                        },
                        {
                            "title": "Passed",
                            "value": str(metrics_data["passed_tests"]),
                            "short": True
                        },
                        {
                            "title": "Failed",
                            "value": str(metrics_data["failed_tests"]),
                            "short": True
                        },
                        {
                            "title": "Pass Rate",
                            "value": f"{pass_rate*100:.1f}%",
                            "short": True
                        },
                        {
                            "title": "Average Duration",
                            "value": f"{metrics_data['average_duration']/1000:.2f}s",
                            "short": True
                        }
                    ],
                    "footer": "Test Automation Pipeline",
                    "ts": int(datetime.now().timestamp())
                }]
            }
            
            # –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞
            response = requests.post(webhook_url, json=message)
            return response.status_code == 200

# –õ–£–ß–®–ò–ï –ü–†–ê–ö–¢–ò–ö–ò –û–¢–ß–ï–¢–ù–û–°–¢–ò:
reporting_best_practices = [
    "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ Allure –¥–ª—è rich reporting",
    "–°–æ–±–∏—Ä–∞–π—Ç–µ performance –º–µ—Ç—Ä–∏–∫–∏ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏",
    "–ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–π—Ç–µ –æ—Ç—á–µ—Ç—ã –≤ CI/CD pipeline",
    "–ù–∞—Å—Ç—Ä–æ–π—Ç–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è",
    "–•—Ä–∞–Ω–∏—Ç–µ –∏—Å—Ç–æ—Ä–∏—é —Ç–µ—Å—Ç–æ–≤ –¥–ª—è trend –∞–Ω–∞–ª–∏–∑–∞",
    "–°–æ–∑–¥–∞–≤–∞–π—Ç–µ executive dashboards –¥–ª—è –º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç–∞",
    "–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–π—Ç–µ –º–µ—Ç—Ä–∏–∫–∏ –≤ monitoring —Å–∏—Å—Ç–µ–º—ã"
]
```

## üöÄ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

### –£—Å–∫–æ—Ä–µ–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤ –≤ CI/CD

```python
# –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò –¢–ï–°–¢–û–í

class TestPerformanceOptimization:
    def __init__(self):
        self.optimization_strategies = {}
        self.parallelization_techniques = {}
    
    def test_parallelization(self):
        """–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤"""
        
        # pytest.ini –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        pytest_ini_content = """
        [tool:pytest]
        addopts = -n auto --dist worksteal
        markers =
            serial: mark test to run serially
            slow: mark test as slow
            fast: mark test as fast
        """
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è xdist –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
        def optimize_xdist_configuration():
            return {
                "processes": "auto",  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤
                "distribution": "worksteal",  # –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–≥—Ä—É–∑–∫–∏
                "max_worker_restart": 3,  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–æ–≤ worker'–æ–≤
                "rsyncdirs": ["src/", "tests/", "config/"],  # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
                "rsyncignore": ["*.pyc", "__pycache__", ".git"]  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º—ã–µ —Ñ–∞–π–ª—ã
            }
    
    def test_sharding(self):
        """Sharding –¥–ª—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–µ—Å—Ç–æ–≤"""
        
        def generate_shard_commands(total_shards=4):
            """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–º–∞–Ω–¥ –¥–ª—è sharding"""
            
            shard_commands = []
            for shard_num in range(1, total_shards + 1):
                command = f"pytest --shard={shard_num}/{total_shards} tests/"
                shard_commands.append(command)
            
            return shard_commands
        
        # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ CI:
        ci_sharding_example = """
        # GitLab CI matrix –¥–ª—è sharding
        test_shards:
          stage: test
          parallel:
            matrix:
              - SHARD: [1/4, 2/4, 3/4, 4/4]
          script:
            - pytest --shard=$SHARD tests/ --junitxml=reports/results-$SHARD.xml
        """
        
        return ci_sharding_example
    
    def selective_test_execution(self):
        """–°–µ–ª–µ–∫—Ç–∏–≤–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤"""
        
        def determine_affected_tests(changed_files):
            """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å"""
            
            test_mapping = {
                "src/user/": ["tests/unit/test_user.py", "tests/api/test_user_api.py"],
                "src/payment/": ["tests/unit/test_payment.py", "tests/integration/test_payment_flow.py"],
                "src/ui/": ["tests/ui/"],
                "requirements.txt": ["tests/"]  # –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
            }
            
            affected_tests = set()
            
            for changed_file in changed_files:
                for source_path, test_files in test_mapping.items():
                    if changed_file.startswith(source_path):
                        affected_tests.update(test_files)
            
            return list(affected_tests)
        
        def git_based_test_selection():
            """–í—ã–±–æ—Ä —Ç–µ—Å—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ Git"""
            
            import subprocess
            
            def get_changed_files(base_branch="origin/main"):
                """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
                result = subprocess.run([
                    "git", "diff", "--name-only", base_branch
                ], capture_output=True, text=True)
                
                return result.stdout.strip().split('\n')
            
            def select_tests_for_changes():
                """–í—ã–±–æ—Ä —Ç–µ—Å—Ç–æ–≤ –¥–ª—è –∑–∞–ø—É—Å–∫–∞"""
                changed_files = get_changed_files()
                affected_tests = determine_affected_tests(changed_files)
                
                if not affected_tests:
                    return ["tests/smoke/"]  # Smoke —Ç–µ—Å—Ç—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                
                return affected_tests
    
    def caching_strategies(self):
        """–°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è"""
        
        caching_configurations = {
            "pip_cache": {
                "paths": ["~/.cache/pip/", ".pip-cache/"],
                "key_template": "${CI_JOB_NAME}-${CI_COMMIT_REF_SLUG}-${CACHE_VERSION}"
            },
            
            "playwright_cache": {
                "paths": ["ms-playwright/", "~/.cache/ms-playwright/"],
                "key_template": "playwright-browsers-${OS}-${PLAYWRIGHT_VERSION}"
            },
            
            "docker_cache": {
                "paths": [".docker-cache/"],
                "key_template": "docker-layers-${CI_COMMIT_SHA}"
            },
            
            "test_results_cache": {
                "paths": ["reports/.cache/"],
                "key_template": "test-results-${TEST_SUITE_HASH}"
            }
        }
        
        return caching_configurations
    
    def resource_optimization(self):
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ä–µ—Å—É—Ä—Å–æ–≤"""
        
        def optimize_docker_images():
            """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è Docker –æ–±—Ä–∞–∑–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–æ–≤"""
            
            optimized_dockerfile = """
            # Multi-stage build –¥–ª—è –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏–∏ —Ä–∞–∑–º–µ—Ä–∞
            FROM python:3.11-slim as base
            RUN apt-get update && apt-get install -y \\
                curl \\
                jq \\
                && rm -rf /var/lib/apt/lists/*
            
            FROM base as builder
            COPY requirements.txt .
            RUN pip wheel --no-cache-dir --no-deps --wheel-dir /wheels -r requirements.txt
            
            FROM base
            COPY --from=builder /wheels /wheels
            RUN pip install --no-cache /wheels/*
            
            # –¢–æ–ª—å–∫–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –¥–ª—è Playwright
            RUN playwright install chromium
            """
            
            return optimized_dockerfile
        
        def resource_limits_configuration():
            """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ª–∏–º–∏—Ç–æ–≤ —Ä–µ—Å—É—Ä—Å–æ–≤"""
            
            return {
                "memory_limit": "4G",      # –õ–∏–º–∏—Ç –ø–∞–º—è—Ç–∏
                "cpu_limit": "2",          # –õ–∏–º–∏—Ç CPU
                "timeout": "30m",          # –¢–∞–π–º–∞—É—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
                "parallel_jobs": 4,        # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ jobs
                "retry_attempts": 2        # –ü–æ–ø—ã—Ç–∫–∏ –ø–æ–≤—Ç–æ—Ä–∞
            }

# –ú–û–ù–ò–¢–û–†–ò–ù–ì –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò:
performance_monitoring = [
    "–û—Ç—Å–ª–µ–∂–∏–≤–∞–π—Ç–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–∞–∂–¥–æ–≥–æ —Ç–µ—Å—Ç–∞",
    "–ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ –∏ CPU",
    "–ê–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —Ç—Ä–µ–Ω–¥—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏",
    "–ò–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä—É–π—Ç–µ –∏ —É—Å—Ç—Ä–∞–Ω—è–π—Ç–µ bottleneck'–∏",
    "–û–ø—Ç–∏–º–∏–∑–∏—Ä—É–π—Ç–µ —Å–∞–º—ã–µ –º–µ–¥–ª–µ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã",
    "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ profiling –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞",
    "–ù–∞—Å—Ç—Ä–æ–π—Ç–µ alerting –¥–ª—è degradation –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"
]
```

## ‚ùì –û—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã —Å—Ç—É–¥–µ–Ω—Ç–æ–≤

### CI/CD –∏ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã

**Q: –ö–∞–∫ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å secrets –≤ CI/CD pipeline?**

A:
```python
# –ë–ï–ó–û–ü–ê–°–ù–ê–Ø –†–ê–ë–û–¢–ê –° SECRETS

class SecureSecretsManagement:
    def __init__(self):
        self.secret_handling_patterns = {}
    
    def environment_variables_approach(self):
        """–†–∞–±–æ—Ç–∞ —Å secrets —á–µ—Ä–µ–∑ environment variables"""
        
        # .env.example —Ñ–∞–π–ª (–±–µ–∑ —Ä–µ–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π)
        env_example = """
        # Database Configuration
        DB_HOST=localhost
        DB_PORT=5432
        DB_NAME=test_db
        DB_USER=db_user
        DB_PASS=your_password_here
        
        # API Keys
        API_KEY=your_api_key_here
        SECRET_KEY=your_secret_key_here
        
        # External Services
        SMTP_HOST=smtp.example.com
        SMTP_USER=email_user
        SMTP_PASS=email_password
        """
        
        # CI/CD –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è secrets
        gitlab_ci_secrets = """
        variables:
          DB_HOST: $DATABASE_HOST
          DB_PORT: $DATABASE_PORT
          DB_NAME: $DATABASE_NAME
          DB_USER: $DATABASE_USER
          DB_PASS: $DATABASE_PASSWORD
          API_KEY: $EXTERNAL_API_KEY
          SECRET_KEY: $APPLICATION_SECRET_KEY
        """
        
        # Python –∫–æ–¥ –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–π —Ä–∞–±–æ—Ç—ã —Å secrets
        def secure_secret_access():
            import os
            from typing import Optional
            
            class SecretManager:
                def __init__(self):
                    self._secrets_cache = {}
                
                def get_secret(self, key: str, default: Optional[str] = None) -> Optional[str]:
                    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ secret"""
                    if key in self._secrets_cache:
                        return self._secrets_cache[key]
                    
                    value = os.getenv(key, default)
                    if value and value != default:
                        # –ú–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –ª–æ–≥–æ–≤
                        self._secrets_cache[key] = value
                        return value
                    return None
                
                def get_required_secret(self, key: str) -> str:
                    """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–≥–æ secret"""
                    value = self.get_secret(key)
                    if not value:
                        raise ValueError(f"Required secret {key} is not set")
                    return value
            
            return SecretManager()
    
    def vault_integration(self):
        """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å HashiCorp Vault"""
        
        def vault_secret_retrieval():
            """–ü–æ–ª—É—á–µ–Ω–∏–µ secrets –∏–∑ Vault"""
            
            import hvac
            
            class VaultClient:
                def __init__(self, vault_url: str, role_id: str, secret_id: str):
                    self.client = hvac.Client(url=vault_url)
                    self.authenticate(role_id, secret_id)
                
                def authenticate(self, role_id: str, secret_id: str):
                    """AppRole –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è"""
                    self.client.auth.approle.login(
                        role_id=role_id,
                        secret_id=secret_id
                    )
                
                def get_secret(self, path: str, key: str) -> str:
                    """–ü–æ–ª—É—á–µ–Ω–∏–µ secret –∏–∑ Vault"""
                    secret_response = self.client.secrets.kv.v2.read_secret_version(
                        path=path
                    )
                    return secret_response['data']['data'][key]
            
            # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ CI/CD
            def ci_secret_injection(vault_client):
                """–ò–Ω—ä–µ–∫—Ü–∏—è secrets –≤ CI environment"""
                secrets = {
                    'DB_PASSWORD': vault_client.get_secret('database', 'password'),
                    'API_KEY': vault_client.get_secret('external-services', 'api_key'),
                    'ENCRYPTION_KEY': vault_client.get_secret('app-config', 'encryption_key')
                }
                
                # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤ environment variables
                for key, value in secrets.items():
                    os.environ[key] = value
                
                return secrets
    
    def kubernetes_secrets(self):
        """–†–∞–±–æ—Ç–∞ —Å Kubernetes secrets"""
        
        def k8s_secret_mounting():
            """–ú–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ secrets –≤ Kubernetes pods"""
            
            k8s_pod_config = """
            apiVersion: v1
            kind: Pod
            metadata:
              name: test-runner
            spec:
              containers:
              - name: test-container
                image: test-image:latest
                envFrom:
                - secretRef:
                    name: test-secrets
                volumeMounts:
                - name: secret-volume
                  mountPath: /etc/secrets
                  readOnly: true
              volumes:
              - name: secret-volume
                secret:
                  secretName: test-certificates
            """
            
            return k8s_pod_config

# –õ–£–ß–®–ò–ï –ü–†–ê–ö–¢–ò–ö–ò –î–õ–Ø SECRETS:
secrets_best_practices = [
    "–ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∫–æ–º–º–∏—Ç—å—Ç–µ –Ω–∞—Å—Ç–æ—è—â–∏–µ secrets –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π",
    "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ secrets management —Å–∏—Å—Ç–µ–º—ã (Vault, AWS Secrets Manager)",
    "–†–æ—Ç–∏—Ä—É–π—Ç–µ secrets —Ä–µ–≥—É–ª—è—Ä–Ω–æ",
    "–û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–π—Ç–µ –¥–æ—Å—Ç—É–ø –∫ secrets –ø–æ –ø—Ä–∏–Ω—Ü–∏–ø—É least privilege",
    "–ú–∞—Å–∫–∏—Ä—É–π—Ç–µ secrets –≤ –ª–æ–≥–∞—Ö –∏ –æ—Ç—á–µ—Ç–∞—Ö",
    "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ä–∞–∑–Ω—ã–µ secrets –¥–ª—è —Ä–∞–∑–Ω—ã—Ö environments",
    "–†–µ–≥—É–ª—è—Ä–Ω–æ –∞—É–¥–∏—Ä—É–π—Ç–µ –¥–æ—Å—Ç—É–ø –∫ secrets"
]
```

## üìã –ü–æ–¥—Ä–æ–±–Ω—ã–π —Ç–∞–π–º–∏–Ω–≥ –∑–∞–Ω—è—Ç–∏–π

### –ó–∞–Ω—è—Ç–∏–µ 6.1: –í–≤–µ–¥–µ–Ω–∏–µ –≤ CI/CD –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (90 –º–∏–Ω—É—Ç)

**0-15 –º–∏–Ω: –¢–µ–æ—Ä–∏—è CI/CD –¥–ª—è —Ç–µ—Å—Ç–æ–≤**
- –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ CI/CD
- –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ —Ç–µ—Å—Ç–æ–≤ –≤ pipeline
- –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö pipeline
- **–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ pipeline**

**15-40 –º–∏–Ω: –ü—Ä–∞–∫—Ç–∏–∫–∞ - –ù–∞—Å—Ç—Ä–æ–π–∫–∞ GitLab CI**
- –°–æ–∑–¥–∞–Ω–∏–µ .gitlab-ci.yml —Ñ–∞–π–ª–∞
- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ stages –∏ jobs
- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è artifacts –∏ caching
- **Live coding pipeline –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏**

**40-65 –º–∏–Ω: Hands-on –ø—Ä–∞–∫—Ç–∏–∫–∞**
- –°—Ç—É–¥–µ–Ω—Ç—ã —Å–æ–∑–¥–∞—é—Ç —Å–≤–æ–∏ pipeline
- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
- –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Ç–µ—Å—Ç–æ–≤—ã–º–∏ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞–º–∏
- **–ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–∞—è –ø–æ–º–æ—â—å –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—è**

**65-80 –º–∏–Ω: Troubleshooting –∏ debugging**
- –¢–∏–ø–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã –≤ CI/CD
- –ú–µ—Ç–æ–¥—ã –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ pipeline issues
- –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
- **–†–∞–∑–±–æ—Ä —Ä–µ–∞–ª—å–Ω—ã—Ö case studies**

**80-90 –º–∏–Ω: –ó–∞–∫—Ä–µ–ø–ª–µ–Ω–∏–µ –∏ –¥–æ–º–∞—à–Ω–µ–µ –∑–∞–¥–∞–Ω–∏–µ**
- –û–±–∑–æ—Ä –ø—Ä–æ–π–¥–µ–Ω–Ω–æ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞
- –û—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã
- –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ –¥–æ–º–∞—à–Ω–µ–≥–æ –∑–∞–¥–∞–Ω–∏—è
- **–ê–Ω–æ–Ω—Å —Å–ª–µ–¥—É—é—â–µ–≥–æ –∑–∞–Ω—è—Ç–∏—è**

---
*–ú–æ–¥—É–ª—å 6 –≥–æ—Ç–æ–≤–∏—Ç —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –∫ production-ready –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è*